{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml-1m'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'preprocessed_dataset'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import settings.config as cfg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "preprocessed_dataset_folder = cfg.preprocessed_dataset_folder\n",
    "individual_rs_strategy = cfg.individual_rs_strategy\n",
    "aggregation_strategies = cfg.aggregation_strategies\n",
    "recommendations_number = cfg.recommendations_number\n",
    "individual_rs_validation_folds_k = cfg.individual_rs_validation_folds_k\n",
    "group_rs_evaluation_folds_k = cfg.group_rs_evaluation_folds_k\n",
    "evaluation_strategy = cfg.evaluation_strategy\n",
    "metrics = cfg.metrics\n",
    "group_types = cfg.group_types\n",
    "\n",
    "display(cfg.dataset_folder,cfg.preprocessed_dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ratings_df = pd.read_csv(preprocessed_dataset_folder+\"/ratings.csv\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "group_composition = pickle.load(open(preprocessed_dataset_folder+\"/group_composition.pkl\", \"rb\"))\n",
    "len(group_composition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train individual RS, Prepare groundtruth, Construct group recs.\n",
    "- it is expected that individual RS are already trained and stored in pkl\n",
    "- it is expected that group recommendations are already generated and stored in pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate GRS for Individualists vs. Collectivist tendencies\n",
    "- individualists RS will more often propose items from user's top-k items w.r.t. RS's predictions\n",
    "- evaluate as hit_rate, relative borda and twin DCG (borda and DCG penalizes relevance of items on lower ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def jaccard_sim(a,b):\n",
    "    return len(a.intersection(b))/len(a.union(b))\n",
    "\n",
    "\n",
    "def process_ind_vs_collect(group_composition,group_recommendations,test_pred_df,topk=20):\n",
    "\n",
    "    hitRate = {}\n",
    "    twinDCG = {}\n",
    "    relativeBorda = {}\n",
    "    hitRateAVG = {}\n",
    "    twinDCGAVG = {}\n",
    "    relativeBordaAVG = {}\n",
    "\n",
    "    for (idx, g) in group_composition.items():\n",
    "        if idx % 50 == 0:\n",
    "            print(\"done \"+str(idx))\n",
    "            \n",
    "        groupRec = group_recommendations[idx]\n",
    "        hitRate[idx] = {}\n",
    "        twinDCG[idx] = {}\n",
    "        relativeBorda[idx] = {}\n",
    "        hitRateAVG[idx] = {}\n",
    "        twinDCGAVG[idx] = {}\n",
    "        relativeBordaAVG[idx] = {}\n",
    "\n",
    "        for (idAlg, groupAlg) in groupRec.items():\n",
    "            hitRate[idx][idAlg] = []\n",
    "            twinDCG[idx][idAlg] = []\n",
    "            relativeBorda[idx][idAlg] = []\n",
    "            hitRateAVG[idx][idAlg] = 0.0\n",
    "            twinDCGAVG[idx][idAlg] = 0.0\n",
    "            relativeBordaAVG[idx][idAlg] = 0.0\n",
    "\n",
    "            groupAlgDF = pd.DataFrame({\"items_g\": groupAlg, \"weight_g\": [1/math.log2(i+2) for i in range(len(groupAlg))], \"weight_borda_g\": [(topk-i)/topk for i in range(len(groupAlg))]})\n",
    "            groupAlgDF.set_index(\"items_g\", inplace=True)\n",
    "\n",
    "            for gm in g[\"group_members\"]:\n",
    "                userData = test_pred_df.loc[test_pred_df.user == gm].sort_values(\"predicted_rating\", ascending=False).iloc[:topk]\n",
    "                idcg = np.array([1/math.log2(i+2)**2 for i in range(len(userData))]).sum()\n",
    "                iBorda = np.array([(topk-i)/topk for i in range(len(userData))]).sum()\n",
    "                #compare groupAlg against individual recommendations for all users\n",
    "                userItems = set(userData.item.values)\n",
    "                groupItems = set(groupAlg)\n",
    "                simValue = jaccard_sim(userItems, groupItems)\n",
    "\n",
    "                hitRate[idx][idAlg].append(simValue)\n",
    "                hitRateAVG[idx][idAlg] += simValue\n",
    "\n",
    "                userData[\"weight\"] = [1/math.log2(i+2) for i in range(len(userData))]\n",
    "                userData[\"weight_borda\"] = [(topk-i)/topk for i in range(len(userData))]\n",
    "                userData = userData.set_index(\"item\")\n",
    "\n",
    "                userData = userData.join(groupAlgDF, how=\"inner\", rsuffix=\"_r\")\n",
    "                userData[\"weightTot\"] = userData[\"weight\"] * userData[\"weight_g\"]\n",
    "                userData[\"weightTotBorda\"] = userData[\"weight_borda\"] * userData[\"weight_borda_g\"]\n",
    "                twDCGVal = userData[\"weightTot\"].sum() / idcg\n",
    "                twBordaVal = userData[\"weightTotBorda\"].sum() / iBorda\n",
    "                \n",
    "                twinDCG[idx][idAlg].append(twDCGVal)\n",
    "                twinDCGAVG[idx][idAlg] += twDCGVal\n",
    "                \n",
    "                relativeBorda[idx][idAlg].append(twBordaVal)\n",
    "                relativeBordaAVG[idx][idAlg] += twBordaVal\n",
    "                #print(userData)\n",
    "\n",
    "            hitRateAVG[idx][idAlg] = hitRateAVG[idx][idAlg] / len(g[\"group_members\"])\n",
    "            twinDCGAVG[idx][idAlg] = twinDCGAVG[idx][idAlg] / len(g[\"group_members\"])\n",
    "            relativeBordaAVG[idx][idAlg] = relativeBordaAVG[idx][idAlg] / len(g[\"group_members\"])\n",
    "\n",
    "\n",
    "        \n",
    "    return (hitRate,hitRateAVG,twinDCG,twinDCGAVG,relativeBorda,relativeBordaAVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_0 LENSKIT_ALS\n",
      "done 0\n",
      "done 50\n",
      "done 100\n",
      "done 150\n",
      "done 200\n",
      "fold_0 LENSKIT_CF_USER\n",
      "done 0\n",
      "done 50\n",
      "done 100\n",
      "done 150\n",
      "done 200\n",
      "fold_0 LENSKIT_CF_ITEM\n",
      "done 0\n",
      "done 50\n",
      "done 100\n",
      "done 150\n",
      "done 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = {}\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "lst = os.listdir(preprocessed_dataset_folder)\n",
    "folds = [i for i in lst if (os.path.isdir(preprocessed_dataset_folder+\"/\"+i) and i.startswith(\"fold\"))]\n",
    "for f in folds:\n",
    "    current_fold = int(f.replace(\"fold_\",\"\"))\n",
    "    path_to_fold = preprocessed_dataset_folder+\"/\"+f\n",
    "    recommenders = [\"LENSKIT_ALS\",\"LENSKIT_CF_USER\", \"LENSKIT_CF_ITEM\"]\n",
    "    res[f] = {}\n",
    "    for r in recommenders:\n",
    "        print(f,r)\n",
    "\n",
    "        path_to_recommender = path_to_fold + \"/\" +r\n",
    "        test_pred_df = pickle.load(open(path_to_recommender+\"/test_pred_df.pkl\", \"rb\"))\n",
    "        group_recommendations = pickle.load(open(path_to_recommender+\"/group_recommendations.pkl\", \"rb\"))\n",
    "        \n",
    "        (hitRate,hitRateAVG,twinDCG,twinDCGAVG,relativeBorda,relativeBordaAVG) = process_ind_vs_collect(group_composition,group_recommendations,test_pred_df)\n",
    "        \n",
    "        gs = []\n",
    "        gt = []\n",
    "        for (idx, g) in group_composition.items():\n",
    "            gt.append(g[\"group_similarity\"])\n",
    "            gs.append(g[\"group_size\"])\n",
    "        \n",
    "        results = (hitRate,hitRateAVG,twinDCG,twinDCGAVG,relativeBorda,relativeBordaAVG,gs,gt)\n",
    "        pickle.dump(results, open(path_to_recommender+\"/results.pkl\", \"wb\"))\n",
    "        res[f][r] = results\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make it relative w.r.t. similarity of user-pairs in the RS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitRateAVG = res[f][\"LENSKIT_ALS\"][1]\n",
    "twinDCGAVG = res[f][\"LENSKIT_ALS\"][3]\n",
    "relativeBordaAVG = res[f][\"LENSKIT_ALS\"][5]\n",
    "gs = res[f][\"LENSKIT_ALS\"][6]\n",
    "gt = res[f][\"LENSKIT_ALS\"][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADD           0.020115\n",
       "MUL           0.016931\n",
       "LMS           0.013526\n",
       "MPL           0.018678\n",
       "GFAR          0.016754\n",
       "EPFuzzDA      0.016950\n",
       "group_size    8.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitRateDF = pd.DataFrame(hitRateAVG).T\n",
    "hitRateDF[\"group_size\"] = gs\n",
    "hitRateDF[\"group_type\"] = gt\n",
    "hitRateDF.loc[((hitRateDF.group_size==8)&(hitRateDF.group_type==\"similar_one_divergent\"))].mean()\n",
    "#hitRateDF.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADD           0.034500\n",
       "MUL           0.032967\n",
       "LMS           0.023692\n",
       "MPL           0.033260\n",
       "GFAR          0.021221\n",
       "EPFuzzDA      0.030792\n",
       "group_size    8.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twinDCGDF = pd.DataFrame(twinDCGAVG).T\n",
    "twinDCGDF[\"group_size\"] = gs\n",
    "twinDCGDF[\"group_type\"] = gt\n",
    "twinDCGDF.loc[((twinDCGDF.group_size==8)&(twinDCGDF.group_type==\"divergent\"))].mean()\n",
    "#twinDCGDF.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADD           0.023905\n",
       "MUL           0.021156\n",
       "LMS           0.014118\n",
       "MPL           0.021602\n",
       "GFAR          0.015783\n",
       "EPFuzzDA      0.019940\n",
       "group_size    8.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relativeBordaDF = pd.DataFrame(relativeBordaAVG).T\n",
    "relativeBordaDF[\"group_size\"] = gs\n",
    "relativeBordaDF[\"group_type\"] = gt\n",
    "relativeBordaDF.loc[relativeBordaDF.group_size==8].mean()\n",
    "#relativeBordaDF.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
